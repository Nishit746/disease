{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8710009,"sourceType":"datasetVersion","datasetId":5224911}],"dockerImageVersionId":30732,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-17T17:16:43.231436Z","iopub.execute_input":"2024-06-17T17:16:43.231858Z","iopub.status.idle":"2024-06-17T17:16:43.242562Z","shell.execute_reply.started":"2024-06-17T17:16:43.231826Z","shell.execute_reply":"2024-06-17T17:16:43.241264Z"},"trusted":true},"execution_count":121,"outputs":[{"name":"stdout","text":"/kaggle/input/geeksd/training_set_features.csv\n/kaggle/input/geeksd/test_set_features.csv\n/kaggle/input/geeksd/training_set_labels.csv\n/kaggle/input/geeksd/submission_format.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n","metadata":{"execution":{"iopub.status.busy":"2024-06-17T17:16:43.244492Z","iopub.execute_input":"2024-06-17T17:16:43.245014Z","iopub.status.idle":"2024-06-17T17:16:43.258363Z","shell.execute_reply.started":"2024-06-17T17:16:43.244951Z","shell.execute_reply":"2024-06-17T17:16:43.257233Z"},"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"code","source":"\n# Load the features and labels\ntrain_features = pd.read_csv('/kaggle/input/geeksd/training_set_features.csv')\ntrain_labels = pd.read_csv('/kaggle/input/geeksd/training_set_labels.csv')\n\n# Merge the features and labels on the common identifier if necessary\ndata = train_features.merge(train_labels, on='respondent_id')\n\n# Display the first few rows of the data\n\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-17T17:16:43.260624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(data.isnull(), cmap='Blues', cbar=False, yticklabels=False, xticklabels=data.columns);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n  if data is None:\n        raise ValueError(\"The DataFrame 'data' is None. Please check the file path and format.\")\ndata.drop(['employment_occupation','employment_industry','health_insurance'], axis=1, inplace=True)\ndata.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(data.isnull(), cmap='Blues', cbar=False, yticklabels=False, xticklabels=data.columns);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sum(data.isna().sum(axis=1) > 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndata.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(data.isnull(), cmap='Blues', cbar=False, yticklabels=False, xticklabels=data.columns);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\ndf_simple_imputer = data.copy()\ncat_cols = [col for col in data.columns if data[col].dtype == 'O']\ncont_cols = [col for col in data.columns if col not in cat_cols]\n\nnumeric_cols = data.select_dtypes(include=['float64', 'int64']).columns\ncategorical_cols = data.select_dtypes(include=['object']).columns\n\nimputer = SimpleImputer(strategy='mean')\n\ndf_simple_imputer[cont_cols] = imputer.fit_transform(data[cont_cols])\nimputer = SimpleImputer(strategy='most_frequent')\n\ndf_simple_imputer[cat_cols] = imputer.fit_transform(data[cat_cols])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(df_simple_imputer.isnull(), cmap='Blues', cbar=False, yticklabels=False, xticklabels=data.columns);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import accuracy_score, classification_report\nX = df_simple_imputer.drop(columns=['xyz_vaccine','seasonal_vaccine'])\ny = df_simple_imputer['xyz_vaccine']\nz = df_simple_imputer['seasonal_vaccine']\n# Separate numerical and categorical columns\nnumeric_cols = X.select_dtypes(include=['float64', 'int64']).columns\ncategorical_cols = X.select_dtypes(include=['object']).columns\n\n# Define preprocessing steps for numeric and categorical data\nnumeric_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='mean')),\n    ('scaler', StandardScaler())\n])\n\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\n# Combine preprocessing steps using ColumnTransformer\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_cols),\n        ('cat', categorical_transformer, categorical_cols)\n    ])\n# Create a pipeline combining preprocessing steps and logistic regression model\nmodel = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('classifier', LinearRegression())\n])\nmodel.fit(X, y)\nmodel.fit(X, z)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/geeksd/test_set_features.csv')\ntest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" if test is None:\n        raise ValueError(\"The DataFrame 'data' is None. Please check the file path and format.\")\ntest.drop(['employment_occupation','employment_industry','health_insurance'], axis=1, inplace=True)\ntest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(test.isnull(), cmap='Blues', cbar=False, yticklabels=False, xticklabels=test.columns);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nsimple_imputer = test.copy()\ncat_cols = [col for col in test.columns if data[col].dtype == 'O']\ncont_cols = [col for col in test.columns if col not in cat_cols]\n\nnumeric_cols = test.select_dtypes(include=['float64', 'int64']).columns\ncategorical_cols = test.select_dtypes(include=['object']).columns\n\nimputer = SimpleImputer(strategy='mean')\n\nsimple_imputer[cont_cols] = imputer.fit_transform(test[cont_cols])\nimputer = SimpleImputer(strategy='most_frequent')\n\nsimple_imputer[cat_cols] = imputer.fit_transform(test[cat_cols])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(simple_imputer.isnull(), cmap='Blues', cbar=False, yticklabels=False, xticklabels=simple_imputer.columns);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(simple_imputer)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_te = pd.read_csv('/kaggle/input/geeksd/submission_format.csv')\ny_true = y_te.h1n1_vaccine\nz_true = y_te.seasonal_vaccine","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, r2_score\n\n# Assuming 'y_true' and 'y_pred' are predictions from a regression model\nmse = mean_squared_error(y_true, y_pred)\nr2 = r2_score(y_true, y_pred)\nme = mean_squared_error(z_true, y_pred)\nr = r2_score(z_true, y_pred)\n\nprint(\"Mean Squared Error: of xyz\", mse)\nprint(\"R-squared:\", r2)\nprint(\"Mean Squared Error: of seasonal\", me)\nprint(\"R-squared:\", r)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}